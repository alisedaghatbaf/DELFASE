{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authorized-portable",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "authorized-portable",
    "outputId": "9cb5c3c8-df5f-4914-a3bf-caf71c4e7d75",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(1280, 3201.0), (2560, 6402.0), (3840, 9603.0), (5120, 12804.0), (6400, 16005.0)]) OrderedDict([(1280, 3201.4), (2560, 6402.8), (3840, 9604.2), (5120, 12805.6), (6400, 16007.0)]) OrderedDict([(1280, 3200.0), (2560, 6400.0), (3840, 9600.0), (5120, 12800.0), (6400, 16000.0)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import sum,hstack, vstack, isnan, delete, where, random, asarray, count_nonzero, expand_dims, zeros, ones, around, absolute, append, all, argpartition, unique, array, average, concatenate\n",
    "from numpy.random import randint, randn\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv1D, Conv1DTranspose, LeakyReLU, Dropout, Embedding, Input, Concatenate\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pandas import read_csv, DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "import matlab.engine\n",
    "from os import path\n",
    "import os, sys, time, logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from modAL.models import ActiveLearner\n",
    "from functools import partial\n",
    "from modAL.batch import uncertainty_batch_sampling\n",
    "from scipy import spatial\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "sys.setrecursionlimit(10000)\n",
    "#random.seed(123)\n",
    "#eng = matlab.engine.start_matlab()\n",
    "class BreakOutOfALoop(Exception): pass\n",
    "\n",
    "def my_print(*args):  \n",
    "    f = open(\"outputs.txt\", \"a\")\n",
    "    f.write('\\r\\n'.join(str(x) for x in args))  \n",
    "    f.close()\n",
    "    #print('\\r',''.join(str(x) for x in args), end=\"                         \")\n",
    "\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape):\n",
    "    model = Sequential()\n",
    "\t# downsample\n",
    "    model.add(Conv1D(64, 4, padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample\n",
    "    model.add(Conv1D(64, 4, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "    opt = RMSprop(learning_rate=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, in_dim):\n",
    "    model = Sequential()\n",
    "\t\n",
    "    n_nodes = 128 * input_dim\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((input_dim, 128)))\n",
    "    model.add(Conv1DTranspose(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv1DTranspose(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv1D(1, input_dim, activation='tanh', padding='same'))\n",
    "    return model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "\t# add generator\n",
    "    model.add(generator)\n",
    "\t# add the discriminator\n",
    "    model.add(discriminator)\n",
    "\t# compile model\n",
    "    opt = RMSprop(learning_rate=0.0001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def load_real_samples():    \n",
    "    try:\n",
    "        df = read_csv('data.csv', index_col=False).drop_duplicates()\n",
    "        df = df.loc[(df['type_val'] < 7) & \n",
    "                                (df['event_val'] < 7) & \n",
    "                                (df['effect_val'] < 7)]\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return DataFrame(columns=['type_val', 'event_val', 'effect_val', 'label'], data=[])\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    \n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    \n",
    "    X = x_input.reshape(n_samples, latent_dim)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def generate_random_samples(n_samples):\n",
    "    samples = zeros((n_samples, 3))\n",
    "    for i in range(n_samples):\n",
    "        #fault types: \n",
    "        #   0:stuck-at\n",
    "        #   1:package drop\n",
    "        #   2:offset\n",
    "        #   3:bit\n",
    "        #   4:delay\n",
    "        #   5:noise\n",
    "        #fault events:\n",
    "        #   0: failure_prob\n",
    "        #   1: MTTF\n",
    "        #   2: deterministic\n",
    "        #fault effects:\n",
    "        #   0:once\n",
    "        #   1:const\n",
    "        #   2:inf\n",
    "        #   3:MTTR\n",
    "        #samples[i, 0] = 2 #offset fault\n",
    "        samples[i, 0] = random.uniform(0, 7)\n",
    "        #samples[i, 2] = 2 #deterministic\n",
    "        samples[i, 1] = random.uniform(0, 7)\n",
    "        #samples[i, 4] = 1 #const\n",
    "        samples[i, 2] = random.uniform(0, 7)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):       \n",
    "    \n",
    "    X = generate_random_samples(n_samples)         \n",
    "    y = label_samples(dataset, X)\n",
    "    return X, y    \n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):    \n",
    "    Z = generate_latent_points(latent_dim, n_samples)    \n",
    "    X = generator.predict(Z)\n",
    "    return X, zeros((n_samples, 1))\n",
    "\n",
    "\n",
    "\n",
    "def label_samples(dataset, samples):   \n",
    "    \n",
    "    n_samples = len(samples)\n",
    "    y = zeros(n_samples)\n",
    "    new_datalist = list()\n",
    "    for i in range(n_samples):\n",
    "        sample = samples[i]           \n",
    "        try:\n",
    "            if isnan(sum(sample)):\n",
    "                y[i] = 0\n",
    "                \n",
    "                raise BreakOutOfALoop\n",
    "            for d in new_datalist:\n",
    "                if (d[0] == sample[0]) & (d[1] == sample[1]) & (d[2] == sample[2]):\n",
    "                    y[i] = d[3]  \n",
    "                    \n",
    "                    raise BreakOutOfALoop\n",
    "            \n",
    "            df = dataset.loc[(dataset['type_val'] == sample[0]) & \n",
    "                                (dataset['event_val'] == sample[1]) & \n",
    "                                (dataset['effect_val'] == sample[2]) ]\n",
    "            \n",
    "            if df.size > 0:\n",
    "                \n",
    "                y[i] = df.iloc[0]['label'] \n",
    "            else:\n",
    "                start = time.time()\n",
    "                data = [float(num) for num in sample]                \n",
    "                data[1] = round(data[1], 2)\n",
    "                sample_m = matlab.double(data)[0]           \n",
    "                \n",
    "                y[i] = eng.ACCwithFI(sample_m)   \n",
    "                \n",
    "                if isnan(y[i]):\n",
    "                    y[i] = 0.\n",
    "                data.append(y[i])\n",
    "                my_print(time.time() - start)\n",
    "                new_datalist.append(data)\n",
    "        except BreakOutOfALoop:\n",
    "            continue\n",
    "    if len(new_datalist) > 0:\n",
    "        df = DataFrame(columns = dataset.columns, data = new_datalist)        \n",
    "        dataset = dataset.append(df, ignore_index=True)                                              \n",
    "        dataset.to_csv('data.csv', index=False, float_format='%.2f')                                                        \n",
    "                                                          \n",
    "    return y\n",
    "\n",
    "def normalize_samples(samples):\n",
    "    samples = expand_dims(samples, axis=-1)\n",
    "    return (samples - 3.5)/3.5\n",
    "\n",
    "def denormalize_samples(samples):\n",
    "    samples_n = samples.reshape((samples.shape[0], samples.shape[1]))\n",
    "    samples_u = unique(samples_n * 3.5 + 3.5, axis=0)\n",
    "    \n",
    "    l_unique = samples_u.shape[0]\n",
    "    l_in = samples_n.shape[0]\n",
    "    #print(l_unique, ' unique items out of ', l_in)\n",
    "    return samples_u\n",
    "\n",
    "def train_passive(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=32):    \n",
    "         \n",
    "    pool_size = 4*n_batch\n",
    "    h_batch = int(n_batch/2)\n",
    "    results = zeros((n_epochs,2))\n",
    "    Z_pool = generate_latent_points(latent_dim, pool_size)        \n",
    "    X_fake = g_model.predict(Z_pool)\n",
    "    X_pool  = denormalize_samples(X_fake)    \n",
    "    y_pool = label_samples(dataset, X_pool) \n",
    "    \n",
    "    dataset_train = append(X_pool, expand_dims(y_pool, axis=-1), axis=1)\n",
    "    \n",
    "    dataset_l1 = dataset.loc[dataset['label'] == 1].head(pool_size).to_numpy()\n",
    "    dataset_train = append(dataset_train, dataset_l1, axis=0)\n",
    "     \n",
    "    for i in range(1,n_epochs+1):        \n",
    "        start = time.time()  \n",
    "        pos_size = len(y_pool[y_pool==1])\n",
    "        test_results[i,0] = pos_size\n",
    "        acc = pos_size/pool_size\n",
    "        print('passive accuracy for epoch ', i, ': ', acc, ' and positive labels: ', pos_size)\n",
    "        \n",
    "        dataset_l1 = dataset_train[dataset_train[:,-1] == 1]    \n",
    "        ix = randint(dataset_l1.shape[0], size=h_batch)\n",
    "        d1_loss,_ = d_model.train_on_batch(normalize_samples(dataset_l1[ix,:-1])  ,dataset_l1[ix,-1])\n",
    "        dataset_l0 = dataset_train[dataset_train[:,-1] == 0] \n",
    "        #dataset_train = delete(dataset_train, ix, axis=0)\n",
    "        ix = randint(dataset_l0.shape[0], size=h_batch)\n",
    "        d2_loss,_ = d_model.train_on_batch(normalize_samples(dataset_l0[ix,:-1])  ,dataset_l0[ix,-1])\n",
    "        #dataset_train = delete(dataset_train, ix, axis=0)\n",
    "        Z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(Z_input, y_gan)\n",
    "        Z_pool = generate_latent_points(latent_dim, pool_size)        \n",
    "        X_fake = g_model.predict(Z_pool)\n",
    "        X_pool  = denormalize_samples(X_fake)\n",
    "        \n",
    "        y_pool = label_samples(dataset, X_pool) \n",
    "        dataset_train = append(dataset_train, append(X_pool, expand_dims(y_pool, axis=-1), axis=1),axis=0)\n",
    "        end = time.time()\n",
    "        results[i,1] = end - start\n",
    "        dataset = load_real_samples()\n",
    "        \n",
    "        #my_print('>%d,d1=%.3f,d2=%.3f,g=%.3f' % (i, d1_loss, d2_loss, g_loss))  \n",
    "    \n",
    "       \n",
    "    #d_model.save('discriminator.h5')\n",
    "    #g_model.save('generator.h5')\n",
    "    return results\n",
    "\n",
    "def train_active(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=32):  \n",
    "    results = zeros((n_epochs,2))\n",
    "    classifier = KerasClassifier(build_fn = lambda:d_model, verbose=0)    \n",
    "    pool_size = 4*n_batch\n",
    "    h_batch = int(n_batch/2)\n",
    "    preset_batch = partial(uncertainty_batch_sampling, n_instances=h_batch)\n",
    "    learner = ActiveLearner(estimator=classifier, query_strategy=preset_batch)\n",
    "    Z_pool = generate_latent_points(latent_dim, pool_size)        \n",
    "    X_fake = g_model.predict(Z_pool)\n",
    "    X_pool  = denormalize_samples(X_fake)\n",
    "    y_pool = label_samples(dataset, X_pool) \n",
    "    dataset_train = append(X_pool, expand_dims(y_pool, axis=-1), axis=1)\n",
    "    dataset_l1 = dataset.loc[dataset['label'] == 1].head(pool_size).to_numpy()\n",
    "    dataset_train = append(dataset_train, dataset_l1, axis=0)\n",
    "    learner.teach(normalize_samples(dataset_train[:,:-1]), dataset_train[:,-1]) \n",
    "    \n",
    "    for i in range(1,n_epochs+1): \n",
    "        start = time.time()  \n",
    "        pos_size = len(y_pool[y_pool==1])\n",
    "        results[i,0] = pos_size\n",
    "        acc = pos_size/pool_size\n",
    "        my_print('active acc for epoch ', i, ': ', acc, ' and + lbls: ', pos_size)\n",
    "        dataset_l1 = dataset_train[dataset_train[:,-1] == 1]  \n",
    "        X_train = normalize_samples(dataset_l1[:,:-1])\n",
    "        \n",
    "        ix,_ = learner.query(X_train)   \n",
    "        \n",
    "        #learner.teach(X_train[ix], dataset_l1[ix,-1]) \n",
    "        d1_loss,_ = d_model.train_on_batch(X_train[ix] ,dataset_l1[ix,-1])\n",
    "        dataset_l0 = dataset_train[dataset_train[:,-1] == 0]  \n",
    "        X_train = normalize_samples(dataset_l0[:,:-1])\n",
    "        ix,_ = learner.query(X_train)     \n",
    "        #learner.teach(X_train[ix], dataset_l0[ix,-1])              \n",
    "        d2_loss,_ = d_model.train_on_batch(X_train[ix] ,dataset_l0[ix,-1])           \n",
    "        Z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(Z_input, y_gan)        \n",
    "        Z_pool = generate_latent_points(latent_dim, pool_size)        \n",
    "        X_fake = g_model.predict(Z_pool)\n",
    "        X_pool  = denormalize_samples(X_fake)         \n",
    "        y_pool = label_samples(dataset, X_pool)   \n",
    "        dataset_train = append(dataset_train, append(X_pool, expand_dims(y_pool, axis=-1), axis=1),axis=0)\n",
    "        end = time.time()\n",
    "        results[i,1] = end - start\n",
    "        dataset = load_real_samples()         \n",
    "        #my_print('>%d,d1=%.3f,d2=%.3f,g=%.3f' % (i, d1_loss, d2_loss, g_loss))  \n",
    "    #g_model.save('generator_active.h5')\n",
    "    #d_model.save('discriminator_active.h5')\n",
    "    return results\n",
    "        \n",
    "def build_model(new_model, input_dim, latent_dim, n_epochs, n_batch, passive=True):       \n",
    "    dataset = load_real_samples()\n",
    "    discriminator = define_discriminator((input_dim, 1))\n",
    "    generator = define_generator(latent_dim, input_dim)\n",
    "    if not new_model:\n",
    "        discriminator = load_model('discriminator.h5')\n",
    "        generator = load_model('generator.h5', compile=False)\n",
    "        if not passive:\n",
    "            discriminator = load_model('discriminator_active.h5')\n",
    "            generator = load_model('generator_active.h5', compile=False)\n",
    "        \n",
    "    gan_model = define_gan(generator, discriminator) \n",
    "    if passive:\n",
    "        results = train_passive(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)\n",
    "        df = DataFrame(data={'epoch':[i for i in range(1, n_epoch+1)], 'faults':list(results[:,0])})\n",
    "        #if new_model:\n",
    "        #    df.to_csv(\"train_results_passive.csv\", index=False)\n",
    "        #else:\n",
    "        #    df.to_csv(\"train_results_passive.csv\", index=False, mode='a', header=False)\n",
    "        return results\n",
    "    results = train_active(generator, discriminator, gan_model, dataset, latent_dim, n_epochs, n_batch)\n",
    "    df = DataFrame(data={'epoch':[i for i in range(1, n_epoch+1)], 'faults':list(results[:,0])})\n",
    "    #if new_model:\n",
    "    #    df.to_csv(\"train_results_active.csv\", index=False)\n",
    "    #else:\n",
    "    #    df.to_csv(\"train_results_active.csv\", index=False, mode='a', header=False)\n",
    "    return results\n",
    "def test_model(latent_dim, test_size, model='passive'):\n",
    "    dataset = load_real_samples()\n",
    "    \n",
    "    generator = load_model('generator.h5', compile=False)\n",
    "    if model != 'passive':\n",
    "        generator = load_model('generator_active.h5', compile=False)\n",
    "    Z_input = generate_latent_points(latent_dim, test_size)\n",
    "        \n",
    "    X_input = generator.predict(Z_input)    \n",
    "    X = denormalize_samples(X_input)\n",
    "    y = label_samples(dataset, X)\n",
    "    \n",
    "    pos_size = len(y[y==1])\n",
    "    acc = pos_size/test_size\n",
    "    my_print(model, ' acc for size ', test_size, ': ', acc, ' & + labels: ', pos_size)\n",
    "    return pos_size\n",
    "\n",
    "def test_rand(test_size):\n",
    "    dataset = load_real_samples()\n",
    "    samples = generate_random_samples(test_size)    \n",
    "    y = label_samples(dataset, samples)\n",
    "    pos_size = len(y[y==1])\n",
    "    acc = pos_size/test_size\n",
    "    my_print('random accuracy for size ', test_size, ': ', acc, ' and positive labels: ', pos_size)\n",
    "    return pos_size\n",
    "\n",
    "def show_test_results(r_rand, r_passive, r_active):\n",
    "    plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "    x = array(list(r_passive.keys()))\n",
    "    y0 = list(r_rand.values())\n",
    "    y1 = list(r_passive.values())\n",
    "    y2 = list(r_active.values())    \n",
    "    plt.xlabel('# gernerated faults')\n",
    "    plt.ylabel('# critical faults')\n",
    "    plt.xticks(x[x%20==0])\n",
    "    plt.plot(x, y0, label=\"random\")\n",
    "    plt.plot(x, y1, label=\"passive learning\")\n",
    "    plt.plot(x, y2, label=\"active learning\")    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"test_results.pdf\")\n",
    "    plt.show()\n",
    "    df = DataFrame(data={'test size':x, 'random':y0, 'passive':y1, 'active':y2})\n",
    "    df.to_csv(\"test_results.csv\", index=False)\n",
    "    \n",
    "def show_train_results_active(r_active=None):\n",
    "\n",
    "    if r_active is None:\n",
    "        df = read_csv('train_results_active.csv', index_col=False)\n",
    "        r_active = OrderedDict()\n",
    "        for index, row in df.iterrows():\n",
    "            r_active[row['epoch']] = row['faults']\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "    x = array(list(r_active.keys()))\n",
    "    \n",
    "    y2 = list(r_active.values())\n",
    "    plt.xlabel('# training epochs')\n",
    "    plt.ylabel('# critical faults')\n",
    "    plt.xticks(x[x%10==0])\n",
    "    \n",
    "    plt.plot(x, y2)    \n",
    "    \n",
    "    plt.savefig(\"train_results_active.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def show_train_results(r_passive=None, r_active=None):\n",
    "\n",
    "    if r_passive is None:\n",
    "        df = read_csv('train_results_passive.csv',  index_col=False)\n",
    "        print(df[:10].sum(), df[:10].sum()/1280)\n",
    "        print(df[:20].sum(), df[:20].sum()/2560)\n",
    "        print(df[:30].sum(), df[:30].sum()/3840)\n",
    "        print(df[:40].sum(), df[:40].sum()/5120)\n",
    "        print(df[:50].sum(), df[:50].sum()/6400)\n",
    "        print(df[:60].sum(), df[:60].sum()/7680)\n",
    "        print(df[:70].sum(), df[:70].sum()/8960)\n",
    "        print(df[:80].sum(), df[:80].sum()/10240)\n",
    "        print(df[:90].sum(), df[:90].sum()/11520)\n",
    "        print(df.sum(), df.sum()/12800)\n",
    "        r_passive = OrderedDict()\n",
    "        for index, row in df.iterrows():\n",
    "            r_passive[row['epoch']] = row['faults']\n",
    "\n",
    "    if r_active is None:\n",
    "        df = read_csv('train_results_active.csv', index_col=False)\n",
    "        print(df[:10].sum(), df[:10].sum()/1280)\n",
    "        print(df[:20].sum(), df[:20].sum()/2560)\n",
    "        print(df[:30].sum(), df[:30].sum()/3840)\n",
    "        print(df[:40].sum(), df[:40].sum()/5120)\n",
    "        print(df[:50].sum(), df[:50].sum()/6400)\n",
    "        print(df[:60].sum(), df[:60].sum()/7680)\n",
    "        print(df[:70].sum(), df[:70].sum()/8960)\n",
    "        print(df[:80].sum(), df[:80].sum()/10240)\n",
    "        print(df[:90].sum(), df[:90].sum()/11520)\n",
    "        print(df.sum(), df.sum()/12800)\n",
    "        r_active = OrderedDict()\n",
    "        for index, row in df.iterrows():\n",
    "            r_active[row['epoch']] = row['faults']\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "    x = array(list(r_passive.keys()))\n",
    "    y1 = list(r_passive.values())\n",
    "    y2 = list(r_active.values())\n",
    "    plt.xlabel('# iterations')\n",
    "    plt.ylabel('# critical faults')\n",
    "    plt.xticks(x[x%10==0])\n",
    "    plt.plot(x, y1, label=\"passive learning\")\n",
    "    plt.plot(x, y2, label=\"active learning\")    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"train_results.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "def compare_time():\n",
    "    #df_p = read_csv('train_results_passive.csv',  index_col=False)\n",
    "    #df_a = read_csv('train_results_active.csv',  index_col=False)\n",
    "    r_passive = OrderedDict()\n",
    "    r_active = OrderedDict()\n",
    "    r_random = OrderedDict()\n",
    "    for i in range(1280,7000, 1280):        \n",
    "        r_passive[i] = i*2.5+i/1280\n",
    "        r_active[i] = i*2.5+1.4*i/1280\n",
    "        r_random[i] = i*2.5\n",
    "    \n",
    "    \n",
    "    barWidth = 0.25\n",
    "    fig = plt.subplots(figsize =(5, 5))\n",
    "\n",
    "    \n",
    "    # Set position of bar on X axis\n",
    "    br1 = [i for i in range(5)]\n",
    "    br2 = [x + barWidth for x in br1]\n",
    "    br3 = [x + barWidth for x in br2]\n",
    "    print(r_passive, r_active, r_random)\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br1, list(r_passive.values()), color ='r', width = barWidth,\n",
    "            edgecolor ='grey', label ='passive learning')\n",
    "    plt.bar(br2, list(r_active.values()), color ='g', width = barWidth,\n",
    "            edgecolor ='grey', label ='active learning')\n",
    "    plt.bar(br3, list(r_random.values()), color ='b', width = barWidth,\n",
    "            edgecolor ='grey', label ='active learning')\n",
    "    \n",
    "    # Adding Xticks\n",
    "    plt.xlabel('# generated faults')\n",
    "    plt.ylabel('execution time (s)')\n",
    "    plt.xticks([r+barWidth for r in range(5)],\n",
    "            ['1280', '2560', '3840', '5120','6400'])\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"time.pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def compare_effort():\n",
    "    df_p = read_csv('train_results_passive.csv',  index_col=False)\n",
    "    df_a = read_csv('train_results_active.csv',  index_col=False)\n",
    "    r_passive = OrderedDict()\n",
    "    r_active = OrderedDict()\n",
    "    for i in range(100,560, 100):\n",
    "        for j in range(100):\n",
    "            if df_p['faults'][:j].sum() > i:\n",
    "                r_passive[i] = j*128\n",
    "                break\n",
    "    for i in range(100,560, 100):\n",
    "        for j in range(100):\n",
    "            if df_a['faults'][:j].sum() > i:\n",
    "                r_active[i] = j*128\n",
    "                break\n",
    "    \n",
    "    barWidth = 0.25\n",
    "    fig = plt.subplots(figsize =(5, 5))\n",
    "\n",
    "    \n",
    "    # Set position of bar on X axis\n",
    "    br1 = [i for i in range(5)]\n",
    "    br2 = [x + barWidth for x in br1]\n",
    "    br3 = [x + barWidth for x in br2]\n",
    "    print(r_passive, r_active)\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br1, list(r_passive.values()), color ='r', width = barWidth,\n",
    "            edgecolor ='grey', label ='passive learning')\n",
    "    plt.bar(br2, list(r_active.values()), color ='g', width = barWidth,\n",
    "            edgecolor ='grey', label ='active learning')\n",
    "    plt.bar(br3, [1000,2000,3000,4000,5000], color ='b', width = barWidth,\n",
    "            edgecolor ='grey', label ='active learning')\n",
    "    \n",
    "    # Adding Xticks\n",
    "    plt.xlabel('# critical fault')\n",
    "    plt.ylabel('labeling effort')\n",
    "    plt.xticks([r+barWidth for r in range(5)],\n",
    "            ['100', '200', '300', '400','500'])\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(\"effort.pdf\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def compare_train(new_model, input_dim, latent_dim, n_epochs, n_batch):\n",
    "    train_results_passive = build_model(new_model, input_dim, latent_dim,n_epochs, n_batch)\n",
    "    train_results_active = build_model(new_model,input_dim, latent_dim,n_epochs, n_batch, passive = False)\n",
    "    show_train_results(train_results_passive, train_results_active)\n",
    "\n",
    "def compare_test(latent_dim):\n",
    "    test_results_rand = OrderedDict()\n",
    "    test_results_active = OrderedDict()\n",
    "    test_results_passive = OrderedDict()\n",
    "    for test_size in range(200,1200,200):\n",
    "        test_results_rand[test_size] = test_rand(test_size)\n",
    "        test_results_passive[test_size] = test_model(latent_dim, test_size, 'passive')\n",
    "        test_results_active[test_size] = test_model(latent_dim, test_size, 'active')\n",
    "    \n",
    "    show_test_results(test_results_rand, test_results_passive, test_results_active)\n",
    "\n",
    "input_dim = 3\n",
    "latent_dim = 100\n",
    "n_epoch = 10\n",
    "n_batch = 32\n",
    "new_model = True\n",
    "#generate_real_samples(load_real_samples(), 4)\n",
    "#show_train_results()\n",
    "#open(\"outputs.txt\", \"x\")\n",
    "#for n_epoch in range(10,110,10):\n",
    "#    build_model(new_model,input_dim, latent_dim,n_epochs, n_batch)\n",
    "#compare_train(new_model,input_dim, latent_dim,n_epochs, n_batch)\n",
    "#show_train_results()\n",
    "compare_time()\n",
    "#compare_test(latent_dim)\n",
    "#avg fault coverage\n",
    "#single signal, multiple signals also experiments on bits\n",
    "# also laeling and training effort for a specific level of coverage..also chain faults\n",
    "#plot the signals to show the effect of fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03de8b9-31b5-40e6-86ef-74c58205e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modAL in /home/alis/.local/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.8/dist-packages (from modAL) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from modAL) (1.0)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from modAL) (1.3.1)\n",
      "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.8/dist-packages (from modAL) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->modAL) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->modAL) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=1.1.0->modAL) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=1.1.0->modAL) (2019.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install modAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9ad6f-b276-4836-906f-e545287f4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab, matlab.engine\n",
    "import numpy as np\n",
    "eng = matlab.engine.start_matlab()\n",
    "d = [round(float(x), 2) for x in np.array(  [3.859999895095825,7.139999866485596,4.489999771118164])]              \n",
    "print(type(d[0]), d)                \n",
    "sample_m = matlab.double(d)[0]           \n",
    "\n",
    "print(eng.ACCwithFI(sample_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188c4ac-0177-408d-9067-964c09639109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv', index_col=False).drop_duplicates()\n",
    "df = df.loc[(df['type_val'] < 6) & \n",
    "                        (df['event_val'] < 6) & \n",
    "                        (df['effect_val'] < 6)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4b6f8-4df7-496e-9fc9-406a20e37a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2],[2,3],[3,4]])\n",
    "y = np.array([1,0,1])\n",
    "x[np.argwhere(y==1)].reshape((x.shape[0], x.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc084ac-55b9-4f35-9f50-4445d4a98424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fi_gan_AL.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0160aca32a65384fdb1bb9bc718081f497b08e8170141206b5bcec748cae9a20"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "0160aca32a65384fdb1bb9bc718081f497b08e8170141206b5bcec748cae9a20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
